{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab3efd3-e873-42b0-8637-a94a499fff74",
   "metadata": {},
   "source": [
    "Jupyter notebook that maps optometrist and ophthalmologist locations across the United States, \n",
    "then draws “zones” of eyecare provider access based on driving distances calculated using Mapbox \n",
    "isochrone API for different geographies of interest (ie. state, county, zip code, census tract).\n",
    "these zones are visualized on a choropleth map by a 'coverage score', a value which represents \n",
    "the percentage of the chosen geography of interest that can access a provider.\n",
    "\n",
    "## limitaions of the program:\n",
    "the mapbox API has a limit of 300 requests per minute and will break if that limit is exceeded.\n",
    "to get around this limition there is a timer function set so to ensure the limit is not exceeded, \n",
    "however there are over 90,000 providers in our dataset and this method is time consuming. \n",
    "It is therefore recommended to subset the dataset for the specific geography and classification of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7dd6c6e-4b55-4613-9954-499f45c572dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import requests\n",
    "#from urllib.request import urlopen\n",
    "import json\n",
    "from shapely.geometry import shape, Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib\n",
    "#from matplotlib import pyplot as plt\n",
    "#import seaborn as sns\n",
    "#plt.style.use('default')\n",
    "import geopandas as gpd\n",
    "#import geodatasets\n",
    "import ast\n",
    "from shapely import wkt\n",
    "#from pyproj import Geod\n",
    "import contextily\n",
    "from collections import defaultdict\n",
    "from shapely.ops import unary_union\n",
    "pd.set_option('display.max_columns', None)\n",
    "#import pyarrow as pyarrow\n",
    "import fastparquet as fastparquet\n",
    "import plotly.express as px\n",
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f70c9b6f-6c17-455a-8e53-c7509ecd534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing vision providers dataset accessible on github\n",
    "providers = pd.read_parquet(\"../notebooks1/vision_providers_minimal.parquet\")\n",
    "\n",
    "# using taxonomy codes to categorize providers (accessible to view here: \n",
    "# https://data.cms.gov/provider-characteristics/medicare-provider-supplier-enrollment/medicare-provider-and-supplier-taxonomy-crosswalk/data\n",
    "# )\n",
    "def classify_provider(taxonomy):\n",
    "    codes = taxonomy.split('|')\n",
    "    for code in codes:\n",
    "        if code.startswith('152'):\n",
    "            return 'Optometry'\n",
    "        if code.startswith('207'):\n",
    "            return 'Ophthalmology'\n",
    "        if code.startswith('156'):\n",
    "            return 'Others'\n",
    "    return 'Unknown'\n",
    "providers['Classification'] = providers['Taxonomy'].apply(classify_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8b2433-26a8-46b9-b7d2-10091ca9038c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2667306/3316137378.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  providers2.drop(columns=['index', 'Entity Type Code', 'Replacement NPI', 'Employer Identification Number (EIN)',\n",
      "/tmp/ipykernel_2667306/3316137378.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  providers2['polygons'] = None\n",
      "/tmp/ipykernel_2667306/3316137378.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  providers2['list of dict'] = None\n",
      "/tmp/ipykernel_2667306/3316137378.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  optom['number of providers at this location'] = optom_merged['count']\n",
      "/tmp/ipykernel_2667306/3316137378.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opht['number of providers at this location'] = opht_merged['count']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60016\n",
      "24735\n"
     ]
    }
   ],
   "source": [
    "# cleaning dataset\n",
    "providers.dropna(subset=['Latitude'], inplace=True)\n",
    "\n",
    "providers2 = providers[providers[\"Entity Type Code\"] == 1]\n",
    "\n",
    "providers2.reset_index(inplace=True)\n",
    "providers2.drop(columns=['index', 'Entity Type Code', 'Replacement NPI', 'Employer Identification Number (EIN)',\n",
    "                         'Provider Organization Name (Legal Business Name)', 'Provider Middle Name', \n",
    "                         'Provider Business Mailing Address Country Code (If outside U.S.)', 'Provider Gender Code',\n",
    "                         'Provider Name Suffix Text', 'Provider Other Organization Name', 'Provider Other Organization Name Type Code',\n",
    "                         'Provider Other Last Name', 'Provider Other First Name', 'Provider Other Middle Name', 'Provider Other Name Prefix Text', \n",
    "                         'Provider Other Name Suffix Text', 'Provider Other Credential Text', 'Provider Other Last Name Type Code', \n",
    "                         'Provider Business Mailing Address Postal Code', 'Authorized Official Last Name', 'Authorized Official First Name', \n",
    "                         'Authorized Official Middle Name', 'Authorized Official Title or Position', 'Authorized Official Telephone Number', \n",
    "                         'Certification Date', 'Taxonomy'], inplace=True)\n",
    "\n",
    "# set up empty columns for the api function later\n",
    "providers2['polygons'] = None\n",
    "providers2['list of dict'] = None\n",
    "\n",
    "# seperating optometrists and ophthalmologists\n",
    "optom = providers2[providers2['Classification'] == 'Optometry']\n",
    "print(len(optom))\n",
    "opht = providers2[providers2['Classification'] == 'Ophthalmology']\n",
    "print(len(opht))\n",
    "\n",
    "# getting number of providers per location\n",
    "unique_optom = pd.DataFrame(optom['Full Address'].value_counts(dropna=False))\n",
    "optom_merged = optom.merge(unique_optom, how='left', on=['Full Address'])\n",
    "optom['number of providers at this location'] = optom_merged['count']\n",
    "\n",
    "unique_opht = pd.DataFrame(opht['Full Address'].value_counts(dropna=False))\n",
    "opht_merged = opht.merge(unique_opht, how='left', on=['Full Address'])\n",
    "opht['number of providers at this location'] = opht_merged['count']\n",
    "\n",
    "# dropping rows with duplicate addresses so that only one provider per address is kept. \n",
    "# reducing the number of entries in the dataframe and therefore the number of requests sent to the api\n",
    "optom1 = optom.drop_duplicates(subset=['Full Address'], ignore_index=True)\n",
    "opht1 = opht.drop_duplicates(subset=['Full Address'], ignore_index=True)\n",
    "\n",
    "# creating geodataframes\n",
    "optom_gdf = gpd.GeoDataFrame(\n",
    "   optom1, geometry=gpd.points_from_xy(optom1.Longitude, optom1.Latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "opht_gdf = gpd.GeoDataFrame(\n",
    "   opht1, geometry=gpd.points_from_xy(opht1.Longitude, opht1.Latitude), crs=\"EPSG:4326\")\n",
    "\n",
    "# you can chose to subset the dataframes for a specific state\n",
    "optom_gdf = optom_gdf[optom_gdf[\"Provider Business Mailing Address State Name\"] == 'IL']\n",
    "opht_gdf = opht_gdf[opht_gdf[\"Provider Business Mailing Address State Name\"] == 'IL']\n",
    "\n",
    "optom_gdf.reset_index(inplace=True)\n",
    "opht_gdf.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06124458-87e9-4b5a-a240-ce90332eff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting up geography datasets\n",
    "# datasets for state and county level can be found on github. census tract datasets\n",
    "# for oklahoma and illinois are also on github. if you want to see census tract data\n",
    "# for a different state, you can download the dataset from here: \n",
    "# https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2020.html#list-tab-790442341\n",
    "\n",
    "# # state level\n",
    "# state = gpd.read_file('../notebooks1/US_State_Boundaries.zip')\n",
    "# state = state.to_crs(\"EPSG:4326\")\n",
    "# state.drop(columns=['FID', 'OBJECTID', 'ORDER_ADM', 'MONTH_ADM', 'DAY_ADM',\n",
    "#                     'PRIM_MILES', 'Shape_Leng', 'Shape__Are', 'Shape__Len'], inplace=True)\n",
    "# state_optom = state\n",
    "# state_opht = state\n",
    "\n",
    "# # county level\n",
    "# county = gpd.read_file('../notebooks1/USA_Counties_(Generalized).zip')\n",
    "# county = county.to_crs(\"EPSG:4326\")\n",
    "# county = county[['NAME', 'STATE_NAME', 'STATE_FIPS', ', CNTY_FIPS', 'FIPS', 'SQMI',\n",
    "#                 'geometry']]\n",
    "# county_optom = county\n",
    "# county_opht = county\n",
    "\n",
    "# census tract level example\n",
    "ILtracts = gpd.read_file('../notebooks1/tl_2020_17_tract (3).zip')\n",
    "ILtracts = ILtracts.to_crs(\"EPSG:4326\")\n",
    "ILtracts.drop(columns=['NAME', 'TRACTCE', 'MTFCC', 'FUNCSTAT', 'ALAND', 'AWATER', \n",
    "                       'INTPTLAT', 'INTPTLON'], inplace=True)\n",
    "ILtracts_opt = ILtracts\n",
    "ILtracts_opht = ILtracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f64e76-22b0-4301-8afe-a8a6486bf7ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function that feeds values from the longitude and latitude columns in providers dataframes\n",
    "# to the api to get driving distance isochrones. works per row\n",
    "\n",
    "def polygonf(row):\n",
    "    \"\"\"\n",
    "    takes longitude and latitude data from their respective columns in vision providers dataframe\n",
    "    requests mapbox api using that data outputs polygon data as a column in vpdf\n",
    "    \"\"\"\n",
    "    apierror = \"Failed to make the API request\"\n",
    "    features = 'no features'\n",
    "    long = row['Longitude']\n",
    "    lat = row['Latitude']\n",
    "# defining mapbox api parameters. adjusting the number in the minutes string will change the distance. \n",
    "# check 'https://docs.mapbox.com/api/navigation/isochrone/' for full documentation\n",
    "    apiurl = 'https://api.mapbox.com/isochrone/v1/mapbox/driving-traffic/'\n",
    "    coord = '%2C'\n",
    "    minutes ='?contours_minutes=15&polygons=true&denoise=1&'\n",
    "    token = 'access_token=sk.eyJ1IjoibXlsZXNuZGlyaXR1IiwiYSI6ImNsanllY2hueTAwbXcza3JraTBkc2Z2bzIifQ.rxgKQl5MA6GIkKLbc4nAvA'\n",
    "    Mapbox = apiurl + str(long) + coord + str(lat) + minutes + token\n",
    "\n",
    "    # requesting data from api\n",
    "    data_response = requests.get(Mapbox)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "    if data_response.status_code == 200:\n",
    "        full_json = data_response.json()\n",
    "       \n",
    "        if \"features\" in full_json:\n",
    "            polygonz = full_json['features'][0]['geometry']\n",
    "\n",
    "            return polygonz\n",
    "        else:\n",
    "            return features\n",
    "    else:\n",
    "        return apierror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4adee3-21fa-4fd8-a656-bef5eae29b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk: 1/7\n",
      "Chunk index: RangeIndex(start=0, stop=300, step=1)\n"
     ]
    }
   ],
   "source": [
    "# timer function using optom_gdf as an example\n",
    "# if you have a lot of data, you can make a copy of this notebook and run another dataset simultaneously.\n",
    "# for this you will need to make a new API key here: https://docs.mapbox.com/playground/isochrone/\n",
    "\n",
    "import time\n",
    "\n",
    "chunk_size = 300\n",
    "delay_seconds = 63\n",
    "\n",
    "total_rows = len(optom_gdf)\n",
    "num_chunks = (total_rows // chunk_size) + 1\n",
    "\n",
    "current_chunk = 0\n",
    "\n",
    "while current_chunk < num_chunks:\n",
    "    start_index = current_chunk * chunk_size\n",
    "    end_index = min((current_chunk + 1) * chunk_size, total_rows)\n",
    "\n",
    "    # Process the chunk of the DataFrame\n",
    "    chunk = optom_gdf.iloc[start_index:end_index]\n",
    "    print(f'Processing chunk: {current_chunk+1}/{num_chunks}')\n",
    "    print(f'Chunk index: {chunk.index}')\n",
    "    chunk['polygons'] = chunk.apply(polygonf, axis=1)\n",
    "    optom_gdf.iloc[start_index:end_index] = chunk\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Processed chunk: {current_chunk+1}/{num_chunks}\")\n",
    "\n",
    "    # Wait for the specified time delay\n",
    "    time.sleep(delay_seconds)\n",
    "\n",
    "    # Move to the next chunk\n",
    "    current_chunk += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebbc94-c0b3-4bdc-97e0-2c9af9f753d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now you should have a dataframe with providers as well as coordinates that represent the driving distance isochrones\n",
    "\n",
    "# here, i recommend saving the new dataframe as a csv as a precaution \n",
    "# this will save you from having to run the timer function again in case jupyter crashes\n",
    "\n",
    "optom_gdf.to_csv('optom_gdf')\n",
    "\n",
    "#converting the api data to active geometry\n",
    "optom_gdf['isochrones'] = [shape(value) if isinstance(value, dict) else None for value in optom_gdf['polygons']]\n",
    "optom_gdf.set_geometry('isochrones', inplace=True)\n",
    "optom_gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "print(optom_gdf.crs)\n",
    "\n",
    "# # test\n",
    "# ax = ILtracts.plot(figsize=(10, 10), color='white', linestyle=':', edgecolor='black')\n",
    "# optom_gdf.plot(ax=ax, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee271b91-df50-4295-98cd-2f872bcb575b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the next 3 cells make up the function that compares the isochrone data to the chosen geography data to calculate accessibility scores\n",
    "# you should be able to run this without changing anything\n",
    "\n",
    "#cdf == gdf of geometry area which you want to get the coverage score\n",
    "#idf == gdf of points for which you want to get an isochrone and dictionary of percent of overlap in cdf areas\n",
    "#scoreString = a string that is the name of the coverage score column you choose\n",
    "#dictString = a string that is the name of the dictionary column you choose\n",
    "#cgs == a string that is the name of the geometry column in the cdf\n",
    "#igs == a string that is the name of the geometry column in the idf\n",
    "#key = a string that is the name of the column in the cdf that you want to represent the key of the dictionary\n",
    "\n",
    "def appendADS(cdf, idf, scoreString, dictString, cgs, igs, key):\n",
    "    #api = MapboxAPI()\n",
    "    cdf[scoreString] = 0.0\n",
    "    cdf['polygons in census'] = np.empty((len(cdf), 0)).tolist()\n",
    "    cdf['area coverage of each polygon in census'] = np.empty((len(cdf), 0)).tolist()\n",
    "    \n",
    "    idf[dictString] = ''\n",
    "    censusAreas = []\n",
    "    global geod \n",
    "    geod = Geod(ellps='WGS84')\n",
    "   \n",
    "    geoSetup(cdf)\n",
    "    geoSetup(idf)\n",
    "   \n",
    "    for index, row in cdf.iterrows():\n",
    "        poly_area, poly_perimeter = geod.geometry_area_perimeter(row[cgs])\n",
    "        poly_area = poly_area*-1\n",
    "        censusAreas.append(poly_area)\n",
    "    \n",
    "    cdf['Area'] = censusAreas\n",
    "   \n",
    "    for i in range(len(idf)):\n",
    "        # Create a new dictionary for tracking isochrones\n",
    "        iso_dict = defaultdict(list)\n",
    "        dictionary = {}\n",
    "        dictionary = check(idf.loc[i ,igs], cdf, cgs, dictionary, key, iso_dict)\n",
    "        idf.loc[i, dictString] = [dictionary]\n",
    "        idf.loc[i, 'iso geometries'] = [iso_dict]\n",
    "        \n",
    "        for j in range(len(cdf)):\n",
    "               \n",
    "            if dictionary.get(cdf.loc[j, key]) != None:\n",
    "                score = cdf.loc[j, scoreString]\n",
    "                cdf.loc[j, scoreString] = score + dictionary.get(cdf.loc[j, key])\n",
    "            \n",
    "    for i in range(len(cdf)):\n",
    "        if len(cdf.loc[i, 'polygons in census']) > 0:\n",
    "            gl = []\n",
    "            cdf.loc[i, 'number of polygons in census tract'] = len(cdf.loc[i, 'polygons in census'][0])\n",
    "            toMerge = (cdf.loc[i, 'polygons in census'][0]).copy()\n",
    "            for tract_key, polygons in toMerge.items():\n",
    "                gl.append(polygons)\n",
    "            merged_geom = unary_union(gl)\n",
    "            merged_area, _ = geod.geometry_area_perimeter(merged_geom)\n",
    "            merged_area *= -1\n",
    "            area_val = merged_area / cdf.loc[i,'Area']\n",
    "            cdf.loc[i, 'percent covered by at least one provider'] = area_val\n",
    "        \n",
    "        if len(cdf.loc[i, 'area coverage of each polygon in census']) > 0:\n",
    "            toAddPerc = 0\n",
    "            toAdd = (cdf.loc[i, 'area coverage of each polygon in census'][0]).copy()\n",
    "            for tract_key, percent in toAdd.items():\n",
    "                toAddPerc = toAddPerc + percent\n",
    "            cdf.loc[i, 'added percentages'] = toAddPerc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361e882-1d44-4cf2-84b4-8c22159da5fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function call\n",
    "appendADS(ILtracts_opt, optom_gdf, 'raw score', 'list of dict', 'geometry', 'isochrones', 'GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053e8a3-b486-4383-8cb7-aab7a2aecd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ILtracts_opt['raw score norm'] = ILtracts_opt['raw score']\n",
    "ILtracts_opt.loc[ILtracts_opt['raw score norm'] > 1, 'raw score norm'] = 1.0\n",
    "ILtracts_opt.drop(columns=['polygons in census', 'area coverage of each polygon in census'], inplace=True)\n",
    "ILtracts_opt['Percentage'] = ILtracts_opt[['raw score norm']]*100\n",
    "\n",
    "ILtracts_opt2 = ILtracts_opt.loc[(ILtracts_opt['raw score norm'] == 0.0)]\n",
    "ILtracts_opt2.reset_index(inplace=True)\n",
    "\n",
    "print(ILtracts_opt.shape)\n",
    "print(ILtracts_opt2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76ec496-6802-420b-bedd-6fdbeda7fee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "map_1 = KeplerGl(height=600, data={'zero access':ILtracts_opt2, 'ILtractscoverage':ILtracts_opt})\n",
    "map_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
